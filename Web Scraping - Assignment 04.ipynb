{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping - ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException \n",
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "\n",
    "\n",
    "A) Rank\n",
    "\n",
    "\n",
    "B) Name\n",
    "\n",
    "\n",
    "C) Artist\n",
    "\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\User\\Desktop\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying url of the webpage\n",
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views (in billons)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>8.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Shape of You\"[25]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"See You Again\"[26]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[29]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                       Title                          Artist  \\\n",
       "0   1.      \"Baby Shark Dance\"[22]  Pinkfong Kids' Songs & Stories   \n",
       "1   2.             \"Despacito\"[24]                      Luis Fonsi   \n",
       "2   3.          \"Shape of You\"[25]                      Ed Sheeran   \n",
       "3   4.         \"See You Again\"[26]                     Wiz Khalifa   \n",
       "4   5.  \"Johny Johny Yes Papa\"[29]                     LooLoo Kids   \n",
       "\n",
       "        Upload Date Views (in billons)  \n",
       "0     June 17, 2016               8.04  \n",
       "1  January 12, 2017               7.23  \n",
       "2  January 30, 2017               5.20  \n",
       "3     April 6, 2015               4.99  \n",
       "4   October 8, 2016               4.87  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigate to required url\n",
    "driver.get(url)\n",
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "date=[]\n",
    "view=[]\n",
    "time.sleep(3)\n",
    "\n",
    "# Scrape data from each match tab\n",
    "nums=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "names=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "artists=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]')\n",
    "views=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]')\n",
    "dates=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]')\n",
    "\n",
    "# Itenrate over teh elements to get the required data\n",
    "for i in [nums,names,artists,views,dates]:\n",
    "    for j in i:\n",
    "        if i == nums:\n",
    "            rank.append(j.text)\n",
    "        if i == names:\n",
    "            name.append(j.text)\n",
    "        if i== artists:\n",
    "            artist.append(j.text)\n",
    "        if i == views:\n",
    "            view.append(j.text)\n",
    "        if i == dates:\n",
    "            date.append(j.text)\n",
    "            \n",
    "# Create data frame of the scraped data\n",
    "wiki_youtube = pd.DataFrame({})\n",
    "wiki_youtube['Rank'] = rank\n",
    "wiki_youtube['Title'] = name\n",
    "wiki_youtube['Artist'] = artist\n",
    "wiki_youtube['Upload Date'] = date\n",
    "wiki_youtube['Views (in billons)'] = view\n",
    "wiki_youtube.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Scrape the details team Indiaâ€™s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "\n",
    "\n",
    "A) Match title (I.e. 1st ODI)\n",
    "\n",
    "\n",
    "B) Series\n",
    "\n",
    "\n",
    "C) Place\n",
    "\n",
    "\n",
    "D) Date\n",
    "\n",
    "\n",
    "E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\User\\Desktop\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying url of the webpage\n",
    "url='https://www.bcci.tv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Time</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>TEST\\nINDIA V ENGLAND 2021</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>09:30 IST</td>\n",
       "      <td>04MARCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>T20I\\nINDIA V ENGLAND 2021</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>19:00 IST</td>\n",
       "      <td>12MARCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>T20I\\nINDIA V ENGLAND 2021</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>19:00 IST</td>\n",
       "      <td>14MARCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>T20I\\nINDIA V ENGLAND 2021</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>19:00 IST</td>\n",
       "      <td>16MARCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>T20I\\nINDIA V ENGLAND 2021</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>19:00 IST</td>\n",
       "      <td>18MARCH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                      Series                             Place  \\\n",
       "0    4th Test  TEST\\nINDIA V ENGLAND 2021  Narendra Modi Stadium, Ahmedabad   \n",
       "1    1st T20I  T20I\\nINDIA V ENGLAND 2021  Narendra Modi Stadium, Ahmedabad   \n",
       "2    2nd T20I  T20I\\nINDIA V ENGLAND 2021  Narendra Modi Stadium, Ahmedabad   \n",
       "3    3rd T20I  T20I\\nINDIA V ENGLAND 2021  Narendra Modi Stadium, Ahmedabad   \n",
       "4    4th T20I  T20I\\nINDIA V ENGLAND 2021  Narendra Modi Stadium, Ahmedabad   \n",
       "\n",
       "        Time     Date  \n",
       "0  09:30 IST  04MARCH  \n",
       "1  19:00 IST  12MARCH  \n",
       "2  19:00 IST  14MARCH  \n",
       "3  19:00 IST  16MARCH  \n",
       "4  19:00 IST  18MARCH  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigate to required url\n",
    "driver.get(url)\n",
    "\n",
    "# Navigate to page\n",
    "driver.find_element_by_xpath('//nav[@class=\"navigation__menu js-navigation-menu\"]/ul/li[1]').click()\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath('//nav[@class=\"navigation__menu js-navigation-menu\"]/ul/li[1]/div/div/ul/li[1]').click()\n",
    "time.sleep(3)\n",
    "title=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time1=[]\n",
    "\n",
    "# Scrapeing\n",
    "titles=driver.find_elements_by_xpath('//strong[@class=\"fixture__name fixture__name--with-margin\"]')\n",
    "tournaments=driver.find_elements_by_xpath('//div[@class=\"fixture__format-strip\"]')\n",
    "places=driver.find_elements_by_xpath('//p[@class=\"fixture__additional-info\"]/span')\n",
    "dates=driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]/div/span')\n",
    "months=driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]/div/div/span[1]')\n",
    "times=driver.find_elements_by_xpath('//div[@class=\"fixture__full-date\"]/div/span[2]')\n",
    "\n",
    "# Iterate over each list to get the data\n",
    "for i in tournaments:\n",
    "    series.append(i.text)\n",
    "for i in titles:\n",
    "    title.append(i.text)\n",
    "for i in places:\n",
    "    place.append(i.text)\n",
    "for i in times:\n",
    "    time1.append(i.text)\n",
    "for i in range(len(dates)):\n",
    "    date.append(dates[i].text+months[i].text)\n",
    "\n",
    "# Create dataframe\n",
    "icc=pd.DataFrame({})\n",
    "icc['Match Title']=title\n",
    "icc['Series']=series\n",
    "icc['Place']=place\n",
    "icc['Time']=time1\n",
    "icc['Date']=date\n",
    "icc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "\n",
    "\n",
    "A) Name\n",
    "\n",
    "\n",
    "B) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\User\\Desktop\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying url of the webpage\n",
    "url='https://www.guru99.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Exception Name  \\\n",
       "0     ElementNotVisibleException   \n",
       "1  ElementNotSelectableException   \n",
       "2         NoSuchElementException   \n",
       "3           NoSuchFrameException   \n",
       "4        NoAlertPresentException   \n",
       "\n",
       "                                         Description  \n",
       "0  This type of Selenium exception occurs when an...  \n",
       "1  This Selenium exception occurs when an element...  \n",
       "2  This Exception occurs if an element could not ...  \n",
       "3  This Exception occurs if the frame target to b...  \n",
       "4  This Exception occurs when you switch to no pr...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigate to required url\n",
    "driver.get(url)\n",
    "\n",
    "# Navigate to selenium page\n",
    "driver.find_element_by_xpath('//div[@class=\"featured-box cloumnsize1\"]/ul[1]/li[3]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Navigate to exceptions page\n",
    "driver.find_element_by_xpath('//div[@class=\"item-page\"]/div[2]/table[5]/tbody/tr[34]/td[1]').click()\n",
    "\n",
    "# Scrape the required data\n",
    "column1=driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[1]')\n",
    "column2=driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[2]')\n",
    "exception_name=[]\n",
    "description=[]\n",
    "\n",
    "# Get test by iterating over tags list\n",
    "for i in column1[1:]:\n",
    "    exception_name.append(i.text)\n",
    "for i in column2[1:]:\n",
    "    description.append(i.text)\n",
    "    \n",
    "# Create dataframe of teh scraped data\n",
    "exceptions=pd.DataFrame({})\n",
    "exceptions['Exception Name']=exception_name\n",
    "exceptions['Description']=description\n",
    "exceptions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "\n",
    "\n",
    "A) Rank\n",
    "\n",
    "\n",
    "B) State\n",
    "\n",
    "\n",
    "C) GSDP(18-19)\n",
    "\n",
    "\n",
    "D) GSDP(17-18)\n",
    "\n",
    "\n",
    "E) Share(2017)\n",
    "\n",
    "\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\User\\Desktop\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying url of the webpage\n",
    "url='http://statisticstimes.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_1718</th>\n",
       "      <th>GSDP_1819</th>\n",
       "      <th>Share 2017</th>\n",
       "      <th>GDP (in billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.88%</td>\n",
       "      <td>398.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.59%</td>\n",
       "      <td>246.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.35%</td>\n",
       "      <td>239.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.92%</td>\n",
       "      <td>227.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.87%</td>\n",
       "      <td>225.798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank          State  GSDP_1718  GSDP_1819 Share 2017 GDP (in billion)\n",
       "0    1    Maharashtra          -  2,632,792     13.88%          398.145\n",
       "1    2     Tamil Nadu  1,845,853  1,630,208      8.59%          246.529\n",
       "2    3  Uttar Pradesh  1,687,818  1,584,764      8.35%          239.656\n",
       "3    4        Gujarat          -  1,502,899      7.92%          227.276\n",
       "4    5      Karnataka  1,631,977  1,493,127      7.87%          225.798"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigate to required url\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Navigate to the statewise gdp page\n",
    "driver.find_element_by_xpath('//div[@class=\"navbar\"]/div[2]').click()\n",
    "time.sleep(1)\n",
    "driver.find_element_by_xpath('//div[@class=\"navbar\"]/div[2]/div/a[3]').click()\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "time.sleep(2)\n",
    "rank=[]\n",
    "state=[]\n",
    "gdsp_1819=[]\n",
    "gdsp_1718=[]\n",
    "share=[]\n",
    "gdp=[]\n",
    "\n",
    "# Scrape the required table\n",
    "ranks=driver.find_elements_by_xpath('//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td[1]')\n",
    "states=driver.find_elements_by_xpath('//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td[2]')\n",
    "gdsp_1718s=driver.find_elements_by_xpath('//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td[3]')\n",
    "gdsp_1819s=driver.find_elements_by_xpath('//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td[4]')\n",
    "shares=driver.find_elements_by_xpath('//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td[5]')\n",
    "gdps=driver.find_elements_by_xpath('//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td[6]')\n",
    "tags=[ranks,states,gdsp_1718s,gdsp_1819s,shares,gdps]\n",
    "\n",
    "# Iterate on each tags list to get data \n",
    "for i in tags:\n",
    "    for j in i:\n",
    "        if i==tags[0]:\n",
    "            rank.append(j.text)\n",
    "        if i==tags[1]:\n",
    "            state.append(j.text)\n",
    "        if i==tags[2]:\n",
    "            gdsp_1718.append(j.text)\n",
    "        if i==tags[3]:\n",
    "            gdsp_1819.append(j.text)\n",
    "        if i==tags[4]:\n",
    "            share.append(j.text)\n",
    "        if i==tags[5]:\n",
    "            gdp.append(j.text)\n",
    "\n",
    "# Create dataframe\n",
    "economy=pd.DataFrame({})\n",
    "economy['Rank']=rank\n",
    "economy['State']=state\n",
    "economy['GSDP_1718']=gdsp_1718\n",
    "economy['GSDP_1819']=gdsp_1819\n",
    "economy['Share 2017']=share\n",
    "economy['GDP (in billion)']=gdp\n",
    "economy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def git_trend(url):\n",
    "    \n",
    "    #getting the website started\n",
    "    driver.get(url)\n",
    "    \n",
    "    #using the search bar for further search\n",
    "    search = driver.find_element_by_xpath(\"//label[@class='form-control input-sm header-search-wrapper p-0 js-chromeless-input-container header-search-wrapper-jump-to position-relative d-flex flex-justify-between flex-items-center']\")\n",
    "    search.send_keys('trending')\n",
    "    search.send_keys(Keys.RETURN)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #creating the empty lists\n",
    "    name = []\n",
    "    description = []\n",
    "    contribute = []\n",
    "    language = []\n",
    "    \n",
    "    #repository name\n",
    "    nam = driver.find_elements_by_xpath(\"//div[@class='f4 text-normal']//a\")\n",
    "    for i in nam:\n",
    "        name.append(i.text)\n",
    "        \n",
    "    #description\n",
    "    desc = driver.find_elements_by_xpath(\"//p[@class='mb-1']\")\n",
    "    for i in desc:\n",
    "        description.append(i.text)\n",
    "        \n",
    "    #contributors\n",
    "    contri = driver.find_elements_by_xpath(\"//a[@class='muted-link']\")\n",
    "    for i in contri:\n",
    "        contribute.append(i.text)\n",
    "        \n",
    "    #language used\n",
    "    lang = driver.find_elements_by_xpath(\"//div[@class='d-flex flex-wrap text-small text-gray']//div[2]/span//span[2]\")\n",
    "    for i in lang:\n",
    "        language.append(i.text)\n",
    "        \n",
    "    #creating the dataframe\n",
    "    df_git = pd.DataFrame({})\n",
    "    df_git['Repository Name'] = name\n",
    "    df_git['Repository Description'] = description\n",
    "    df_git['Contributors'] = contribute\n",
    "    \n",
    "    return df_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Name</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iam-abbas/Reddit-Stock-Trends</td>\n",
       "      <td>Fetch currently trending stocks on Reddit</td>\n",
       "      <td>1.3k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mbadry1/Trending-Deep-Learning</td>\n",
       "      <td>Top 100 trending deep learning repositories so...</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datawrangling/trendingtopics</td>\n",
       "      <td>Rails app for tracking trends in server logs -...</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GeneralMills/pytrends</td>\n",
       "      <td>Pseudo API for Google Trends</td>\n",
       "      <td>2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vitalets/github-trending-repos</td>\n",
       "      <td>Track GitHub trending repositories in your fav...</td>\n",
       "      <td>2.1k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d3/d3</td>\n",
       "      <td>Bring data to life with SVG, Canvas and HTML. ...</td>\n",
       "      <td>95.7k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rnoelle/trendingTrivia</td>\n",
       "      <td>A project using angular to bring static HTML/C...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nightonke/GithubWidget</td>\n",
       "      <td>Contributions, stars, followers, trending etc....</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>huchenme/github-trending-api</td>\n",
       "      <td>The missing APIs for GitHub trending projects ...</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ophobe/trending</td>\n",
       "      <td>Dataset of trending repositories on GitHub</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Repository Name  \\\n",
       "0   iam-abbas/Reddit-Stock-Trends   \n",
       "1  mbadry1/Trending-Deep-Learning   \n",
       "2    datawrangling/trendingtopics   \n",
       "3           GeneralMills/pytrends   \n",
       "4  vitalets/github-trending-repos   \n",
       "5                           d3/d3   \n",
       "6          rnoelle/trendingTrivia   \n",
       "7          Nightonke/GithubWidget   \n",
       "8    huchenme/github-trending-api   \n",
       "9                 ophobe/trending   \n",
       "\n",
       "                              Repository Description Contributors  \n",
       "0          Fetch currently trending stocks on Reddit         1.3k  \n",
       "1  Top 100 trending deep learning repositories so...          539  \n",
       "2  Rails app for tracking trends in server logs -...          353  \n",
       "3                       Pseudo API for Google Trends           2k  \n",
       "4  Track GitHub trending repositories in your fav...         2.1k  \n",
       "5  Bring data to life with SVG, Canvas and HTML. ...        95.7k  \n",
       "6  A project using angular to bring static HTML/C...            2  \n",
       "7  Contributions, stars, followers, trending etc....          698  \n",
       "8  The missing APIs for GitHub trending projects ...          609  \n",
       "9         Dataset of trending repositories on GitHub           56  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://github.com/'\n",
    "git_trend(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https://www.billiboard.com/\n",
    "You have to find the following details:\n",
    "\n",
    "\n",
    "A) Song name\n",
    "\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\User\\Desktop\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying url of the webpage\n",
    "url=\"https://www.billboard.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>artist</th>\n",
       "      <th>last_week_rank</th>\n",
       "      <th>peak_rank</th>\n",
       "      <th>no_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drivers License</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Up</td>\n",
       "      <td>Cardi B</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go Crazy</td>\n",
       "      <td>Chris Brown &amp; Young Thug</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34+35</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                    artist last_week_rank peak_rank  \\\n",
       "0  Drivers License            Olivia Rodrigo                        1   \n",
       "1               Up                   Cardi B                        5   \n",
       "2         Go Crazy  Chris Brown & Young Thug                        8   \n",
       "3            34+35             Ariana Grande              2         2   \n",
       "4  Blinding Lights                The Weeknd              4         1   \n",
       "\n",
       "  no_of_week  \n",
       "0          1  \n",
       "1          2  \n",
       "2          3  \n",
       "3         17  \n",
       "4         64  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigate to required url\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "# Acquire on top100 tab\n",
    "driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[2]/nav/ul/li[3]/a').click()\n",
    "name=[]\n",
    "artist=[]\n",
    "last_week_rank=[]\n",
    "peak_rank=[]\n",
    "no_of_week=[]\n",
    "\n",
    "# Scrape the required data\n",
    "song_names=driver.find_elements_by_xpath('//ol[@class=\"chart-list__elements\"]/li/button/span[2]/span[1]')\n",
    "artists=driver.find_elements_by_xpath('//ol[@class=\"chart-list__elements\"]/li/button/span[2]/span[2]')\n",
    "last_weeks=driver.find_elements_by_xpath('//ol[@class=\"chart-list__elements\"]/li/button/div/div[1]')\n",
    "peaks=driver.find_elements_by_xpath('//ol[@class=\"chart-list__elements\"]/li/button/div/div[2]')\n",
    "no_of_weeks=driver.find_elements_by_xpath('//ol[@class=\"chart-list__elements\"]/li/button/div/div[3]')\n",
    "\n",
    "# Iterate on each tags list to get data \n",
    "for i in [song_names,artists,last_weeks,peaks,no_of_weeks]:\n",
    "    for j in i:\n",
    "        if i==song_names:\n",
    "            name.append(j.text)\n",
    "        if i==artists:\n",
    "            artist.append(j.text)\n",
    "        if i==last_weeks:\n",
    "            last_week_rank.append(j.text)\n",
    "        if i==peaks:\n",
    "            peak_rank.append(j.text)\n",
    "        if i==no_of_weeks:\n",
    "            no_of_week.append(j.text)\n",
    "\n",
    "# Create dataframe            \n",
    "billboard=pd.DataFrame({})\n",
    "billboard['name']=name\n",
    "billboard['artist']=artist\n",
    "billboard['last_week_rank']=last_week_rank\n",
    "billboard['peak_rank']=peak_rank\n",
    "billboard['no_of_week']=no_of_week\n",
    "billboard.head()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "\n",
    "\n",
    "A) Name\n",
    "\n",
    "\n",
    "B) Designation\n",
    "\n",
    "\n",
    "C) Company\n",
    "\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'Data Scientist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naukri_data(search_option):\n",
    "    \n",
    "    #getting the website\n",
    "    driver.get('https://www.naukri.com/')\n",
    "    \n",
    "    #getting to the required webpage\n",
    "    search = driver.find_element_by_xpath(\"//div[@class='inpWrap']/input\")\n",
    "    search.send_keys(search_option)\n",
    "    search.send_keys(Keys.RETURN)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    #creating empty lists\n",
    "    name = []\n",
    "    company = []\n",
    "    designation = []\n",
    "    location = []\n",
    "    skill = []\n",
    "    \n",
    "    #name\n",
    "    nam = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    for i in nam:\n",
    "        name.append(i.text)\n",
    "        \n",
    "    #company\n",
    "    comp = driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    for i in comp:\n",
    "        company.append(i.text)\n",
    "        \n",
    "    #location\n",
    "    loc = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\")\n",
    "    for i in loc:\n",
    "        location.append(i.text)\n",
    "        \n",
    "    #designation\n",
    "    desg = driver.find_elements_by_xpath(\"//div[@class='job-description fs12 grey-text']\")\n",
    "    for i in desg:\n",
    "        designation.append(i.text)\n",
    "        \n",
    "    #skill\n",
    "    skil = driver.find_elements_by_xpath(\"//ul[@class='tags has-description']\")\n",
    "    for i in skil:\n",
    "        skill.append(list(i.text))\n",
    "        \n",
    "    #creating the dataframe\n",
    "    df_naukri = pd.DataFrame({})\n",
    "    df_naukri['Name'] = name\n",
    "    df_naukri['Company'] = company\n",
    "    df_naukri['Location'] = location\n",
    "    df_naukri['Designation'] = designation\n",
    "    df_naukri['Skill'] = skill\n",
    "    \n",
    "    return df_naukri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architect/ Lead/ Senior/ Analyst - Data Scient...</td>\n",
       "      <td>ZETTAMINE LABS PRIVATE LIMITED</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Job Title: Architect/ Lead/ Senior/ AnalystJob...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Python/ MATLAB/ Machine Learn...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BS / MS/PhD in Computer Science, Statistics, A...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BS/ MS/ PhD in Computer Science, Statistics, A...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning (Commerce BU)</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Roles and ResponsibilitiesUnder guidance, or i...</td>\n",
       "      <td>[D, a, t, a,  , S, c, i, e, n, c, e, \\n, D, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning/Python</td>\n",
       "      <td>CarbyneTech India</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>You have at least 2 year experience, ideally w...</td>\n",
       "      <td>[P, r, e, d, i, c, t, i, v, e,  , M, o, d, e, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Atos Syntel Private Limited</td>\n",
       "      <td>Chennai, Pune, Mumbai, Bengaluru</td>\n",
       "      <td>Working experience in Artificial Intelligence,...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, J, a, v, a, \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>BE or MS or PhD degree in Computer Science, Ar...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, J, a, v, a, \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>Role Sr. Data ScientistExp. 12 â€“ 20 yearsLocat...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, J, a, v, a, \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>Experience with application development practi...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, J, a, v, a, \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>Logical and Analytical skills must be really s...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Analyst/Data Scientist</td>\n",
       "      <td>Suzlon Energy Limited</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Required Skills: Expert level knowledge of Pyt...</td>\n",
       "      <td>[B, i, g,  , D, a, t, a,  , A, n, a, l, y, t, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist and Senior Data Scientist Acade...</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Graduate with an exceptional academic track re...</td>\n",
       "      <td>[T, a, b, l, e, a, u, \\n, M, a, c, h, i, n, e,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sr. Analyst-Data Scientist</td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Responsibilities : - Understanding the project...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sr . Data Scientist</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>A bachelor s degree in engineering or science ...</td>\n",
       "      <td>[P, r, o, d, u, c, t,  , m, a, n, a, g, e, m, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DATA SCIENTIST / MACHINE LEARNING EXPERT</td>\n",
       "      <td>Spectrus</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Good applied statistics skills, such as distri...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, T, e, s, t, i,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Associate Data Scientist | 0-2 Years | Gurgaon</td>\n",
       "      <td>Xtage Technologies Private Limited</td>\n",
       "      <td>Delhi NCR, Gurgaon</td>\n",
       "      <td>Please note that the position is open for cand...</td>\n",
       "      <td>[A, d, v, a, n, c, e, d,  , A, n, a, l, y, t, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Artificial Intelligence Analyst/Data Scientist</td>\n",
       "      <td>TalentCo Search Pvt Ltd</td>\n",
       "      <td>Mumbai, Bengaluru</td>\n",
       "      <td>Should have at-least 1 end-to-end ML project e...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Viaprom Technologies Pvt Ltd</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Extensive experience in Machine learning algor...</td>\n",
       "      <td>[R, \\n, S, A, S,  , S, Q, L, \\n, S, A, S, \\n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tech Mahindra is hiring For Data Scientist- Ba...</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Proficiency in cleaning, visualizing, analysin...</td>\n",
       "      <td>[P, r, e, d, i, c, t, i, v, e,  , M, o, d, e, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sr. Data Scientist-Machine Learning</td>\n",
       "      <td>Lending Tree Research Services LLP</td>\n",
       "      <td>Ahmedabad(Makarba)</td>\n",
       "      <td>Masters degree is a plusLooking for someone wi...</td>\n",
       "      <td>[I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0   Architect/ Lead/ Senior/ Analyst - Data Scient...   \n",
       "1   Data Scientist - Python/ MATLAB/ Machine Learn...   \n",
       "2   Lead Data Scientist - Machine Learning/ Data M...   \n",
       "3     Data Scientist - Machine Learning (Commerce BU)   \n",
       "4            Data Scientist - Machine Learning/Python   \n",
       "5                                      Data Scientist   \n",
       "6      Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "7      Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "8              Senior Data Scientist - NLP/ Python/ R   \n",
       "9   Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "10                        Data Analyst/Data Scientist   \n",
       "11  Data Scientist and Senior Data Scientist Acade...   \n",
       "12                         Sr. Analyst-Data Scientist   \n",
       "13                                Sr . Data Scientist   \n",
       "14           DATA SCIENTIST / MACHINE LEARNING EXPERT   \n",
       "15     Associate Data Scientist | 0-2 Years | Gurgaon   \n",
       "16     Artificial Intelligence Analyst/Data Scientist   \n",
       "17                              Senior Data Scientist   \n",
       "18  Tech Mahindra is hiring For Data Scientist- Ba...   \n",
       "19                Sr. Data Scientist-Machine Learning   \n",
       "\n",
       "                               Company  \\\n",
       "0       ZETTAMINE LABS PRIVATE LIMITED   \n",
       "1         Wrackle Technologies Pvt Ltd   \n",
       "2         Wrackle Technologies Pvt Ltd   \n",
       "3    BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "4                    CarbyneTech India   \n",
       "5          Atos Syntel Private Limited   \n",
       "6                   Tech Mahindra Ltd.   \n",
       "7                   Tech Mahindra Ltd.   \n",
       "8                   AVI Consulting LLP   \n",
       "9                             CES Ltd.   \n",
       "10               Suzlon Energy Limited   \n",
       "11              RANDSTAD INDIA PVT LTD   \n",
       "12                    Mindtree Limited   \n",
       "13                              NetApp   \n",
       "14                            Spectrus   \n",
       "15  Xtage Technologies Private Limited   \n",
       "16             TalentCo Search Pvt Ltd   \n",
       "17        Viaprom Technologies Pvt Ltd   \n",
       "18                   tech mahindra ltd   \n",
       "19  Lending Tree Research Services LLP   \n",
       "\n",
       "                                             Location  \\\n",
       "0                                           Hyderabad   \n",
       "1                                           Bengaluru   \n",
       "2                                           Bengaluru   \n",
       "3                                           Bengaluru   \n",
       "4                                           Hyderabad   \n",
       "5                    Chennai, Pune, Mumbai, Bengaluru   \n",
       "6                                     Pune, Bengaluru   \n",
       "7                                     Pune, Bengaluru   \n",
       "8                                Bengaluru, Hyderabad   \n",
       "9   Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "10                                               Pune   \n",
       "11                                          Bengaluru   \n",
       "12                                          Bengaluru   \n",
       "13                                          Bengaluru   \n",
       "14                                          Bengaluru   \n",
       "15                                 Delhi NCR, Gurgaon   \n",
       "16                                  Mumbai, Bengaluru   \n",
       "17                                             Mumbai   \n",
       "18                                          Bengaluru   \n",
       "19                                 Ahmedabad(Makarba)   \n",
       "\n",
       "                                          Designation  \\\n",
       "0   Job Title: Architect/ Lead/ Senior/ AnalystJob...   \n",
       "1   BS / MS/PhD in Computer Science, Statistics, A...   \n",
       "2   BS/ MS/ PhD in Computer Science, Statistics, A...   \n",
       "3   Roles and ResponsibilitiesUnder guidance, or i...   \n",
       "4   You have at least 2 year experience, ideally w...   \n",
       "5   Working experience in Artificial Intelligence,...   \n",
       "6   BE or MS or PhD degree in Computer Science, Ar...   \n",
       "7   Role Sr. Data ScientistExp. 12 â€“ 20 yearsLocat...   \n",
       "8   Experience with application development practi...   \n",
       "9   Logical and Analytical skills must be really s...   \n",
       "10  Required Skills: Expert level knowledge of Pyt...   \n",
       "11  Graduate with an exceptional academic track re...   \n",
       "12  Responsibilities : - Understanding the project...   \n",
       "13  A bachelor s degree in engineering or science ...   \n",
       "14  Good applied statistics skills, such as distri...   \n",
       "15  Please note that the position is open for cand...   \n",
       "16  Should have at-least 1 end-to-end ML project e...   \n",
       "17  Extensive experience in Machine learning algor...   \n",
       "18  Proficiency in cleaning, visualizing, analysin...   \n",
       "19  Masters degree is a plusLooking for someone wi...   \n",
       "\n",
       "                                                Skill  \n",
       "0   [I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...  \n",
       "1   [I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...  \n",
       "2   [I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...  \n",
       "3   [D, a, t, a,  , S, c, i, e, n, c, e, \\n, D, a,...  \n",
       "4   [P, r, e, d, i, c, t, i, v, e,  , M, o, d, e, ...  \n",
       "5   [I, T,  , S, k, i, l, l, s, \\n, J, a, v, a, \\n...  \n",
       "6   [I, T,  , S, k, i, l, l, s, \\n, J, a, v, a, \\n...  \n",
       "7   [I, T,  , S, k, i, l, l, s, \\n, J, a, v, a, \\n...  \n",
       "8   [I, T,  , S, k, i, l, l, s, \\n, J, a, v, a, \\n...  \n",
       "9   [I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...  \n",
       "10  [B, i, g,  , D, a, t, a,  , A, n, a, l, y, t, ...  \n",
       "11  [T, a, b, l, e, a, u, \\n, M, a, c, h, i, n, e,...  \n",
       "12  [I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...  \n",
       "13  [P, r, o, d, u, c, t,  , m, a, n, a, g, e, m, ...  \n",
       "14  [I, T,  , S, k, i, l, l, s, \\n, T, e, s, t, i,...  \n",
       "15  [A, d, v, a, n, c, e, d,  , A, n, a, l, y, t, ...  \n",
       "16  [I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...  \n",
       "17  [R, \\n, S, A, S,  , S, Q, L, \\n, S, A, S, \\n, ...  \n",
       "18  [P, r, e, d, i, c, t, i, v, e,  , M, o, d, e, ...  \n",
       "19  [I, T,  , S, k, i, l, l, s, \\n, P, y, t, h, o,...  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = 'Data Scientist'\n",
    "naukri_data(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "You have to find the following details:\n",
    "\n",
    "\n",
    "A) Book name\n",
    "\n",
    "\n",
    "B) Author name\n",
    "\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\User\\Desktop\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying url of the webpage\n",
    "url=\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>sales</th>\n",
       "      <th>publisher</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title         author      sales  \\\n",
       "0                          Da Vinci Code,The     Brown, Dan  5,094,805   \n",
       "1       Harry Potter and the Deathly Hallows  Rowling, J.K.  4,475,152   \n",
       "2   Harry Potter and the Philosopher's Stone  Rowling, J.K.  4,200,654   \n",
       "3  Harry Potter and the Order of the Phoenix  Rowling, J.K.  4,179,479   \n",
       "4                       Fifty Shades of Grey   James, E. L.  3,758,936   \n",
       "\n",
       "      publisher                        genre  \n",
       "0    Transworld  Crime, Thriller & Adventure  \n",
       "1    Bloomsbury           Children's Fiction  \n",
       "2    Bloomsbury           Children's Fiction  \n",
       "3    Bloomsbury           Children's Fiction  \n",
       "4  Random House              Romance & Sagas  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigate to required url\n",
    "driver.get(url)\n",
    "title=[]\n",
    "author=[]\n",
    "volume=[]\n",
    "publisher=[]\n",
    "genre=[]\n",
    "\n",
    "# Scrape the details from the table\n",
    "column1=driver.find_elements_by_xpath('//div[@class=\"embed block\"]/table/tbody/tr/td[2]')\n",
    "column2=driver.find_elements_by_xpath('//div[@class=\"embed block\"]/table/tbody/tr/td[3]')\n",
    "column3=driver.find_elements_by_xpath('//div[@class=\"embed block\"]/table/tbody/tr/td[4]')\n",
    "column4=driver.find_elements_by_xpath('//div[@class=\"embed block\"]/table/tbody/tr/td[5]')\n",
    "column5=driver.find_elements_by_xpath('//div[@class=\"embed block\"]/table/tbody/tr/td[6]')\n",
    "\n",
    "# Iterate over each tags list to get text \n",
    "for i in [column1,column2,column3,column4,column5]:\n",
    "    for j in i:\n",
    "        if i==column1:\n",
    "            title.append(j.text)\n",
    "        if i==column2:\n",
    "            author.append(j.text)\n",
    "        if i==column3:\n",
    "            volume.append(j.text)\n",
    "        if i==column4:\n",
    "            publisher.append(j.text)\n",
    "        if i==column5:\n",
    "            genre.append(j.text)\n",
    "\n",
    "# Create dataframe           \n",
    "books=pd.DataFrame({})\n",
    "books['title']=title\n",
    "books['author']=author\n",
    "books['sales']=volume\n",
    "books['publisher']=publisher\n",
    "books['genre']=genre\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "\n",
    "\n",
    "A) Name\n",
    "\n",
    "\n",
    "B) Year span\n",
    "\n",
    "\n",
    "C) Genre\n",
    "\n",
    "\n",
    "D) Run time\n",
    "\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\User\\Desktop\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying url of the webpage\n",
    "url=\"https://www.imdb.com/list/ls095964455/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>span</th>\n",
       "      <th>genre</th>\n",
       "      <th>run_time</th>\n",
       "      <th>rating</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011â€“2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,777,549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016â€“ )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>828,228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010â€“ )</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>856,447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017â€“2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>257,112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014â€“2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>217,606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title         span                     genre run_time rating  \\\n",
       "0   Game of Thrones  (2011â€“2019)  Action, Adventure, Drama   57 min    9.3   \n",
       "1   Stranger Things     (2016â€“ )    Drama, Fantasy, Horror   51 min    8.7   \n",
       "2  The Walking Dead     (2010â€“ )   Drama, Horror, Thriller   44 min    8.2   \n",
       "3    13 Reasons Why  (2017â€“2020)  Drama, Mystery, Thriller   60 min    7.6   \n",
       "4           The 100  (2014â€“2020)    Drama, Mystery, Sci-Fi   43 min    7.6   \n",
       "\n",
       "        vote  \n",
       "0  1,777,549  \n",
       "1    828,228  \n",
       "2    856,447  \n",
       "3    257,112  \n",
       "4    217,606  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigate to required url\n",
    "driver.get(url)\n",
    "title=[]\n",
    "span=[]\n",
    "genre=[]\n",
    "run_time=[]\n",
    "rating=[]\n",
    "vote=[]\n",
    "\n",
    "# Scrape the details from the table\n",
    "titles=driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/h3/a')\n",
    "spans=driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/h3/span[2]')\n",
    "genres=driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/p/span[5]')\n",
    "run_ts=driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/p/span[3]')\n",
    "ratings=driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/div/div/span[2]')\n",
    "votes=driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/p[4]/span[2]')\n",
    "\n",
    "# Iterate over each tags list to get data \n",
    "for i in [titles,spans,genres,run_ts,ratings,votes]:\n",
    "    for j in i:\n",
    "        if i==titles:\n",
    "            title.append(j.text)\n",
    "        if i==spans:\n",
    "            span.append(j.text)\n",
    "        if i==genres:\n",
    "            genre.append(j.text)\n",
    "        if i==run_ts:\n",
    "            run_time.append(j.text)\n",
    "        if i==ratings:\n",
    "            rating.append(j.text)\n",
    "        if i==votes:\n",
    "            vote.append(j.text)\n",
    "            \n",
    "# Create dataframe of teh acquired data \n",
    "imdb_shows=pd.DataFrame({})\n",
    "imdb_shows['title']=title\n",
    "imdb_shows['span']=span\n",
    "imdb_shows['genre']=genre\n",
    "imdb_shows['run_time']=run_time\n",
    "imdb_shows['rating']=rating\n",
    "imdb_shows['vote']=vote\n",
    "imdb_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
